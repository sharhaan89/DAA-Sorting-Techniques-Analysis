Experimental Setup
1. Machine Specifications:

Processor: 13th Gen Intel(R) Core(TM) i5-1335U   1.30 GHz

RAM: 16 GB

Operating System: Windows 10 

Compiler: GCC 

2. Timing Mechanism:

We used a high-resolution timer for all experiments.
On POSIX systems, the clock_gettime() function with the CLOCK_MONOTONIC flag was used.
On Windows systems, QueryPerformanceCounter() was used.
The measured time is reported in seconds (with microsecond precision).

3. Repetition of Experiments:

To obtain stable measurements and account for system load variations, each experiment (i.e., sorting a given input) was repeated 10 times.
The reported time for each test case is the average execution time over these 10 runs.
A similar averaging was performed for counting comparisons (where applicable).

4. Reported Times:

For each input size and each algorithm, we report the average execution time in seconds.
For comparison-based algorithms, we also report the average number of comparisons.
For non-comparison-based sorts (like Radix Sort), only execution time is reported.

5. Input Data Selection:

Test Case Sizes:
The input sizes were chosen to cover a range from small to large. For instance, we tested arrays ranging from 1,000 to 10,000 elements (or larger in the extended experiments).

Types of Inputs:

Best-Case Inputs:
For algorithms that perform very efficiently on nearly sorted data (e.g., Insertion Sort), best-case inputs were generated by sorting the randomly generated data in increasing order.
Worst-Case Inputs:
Worst-case inputs were generated by sorting the data in decreasing order (reverse sorted), which in many cases (such as Insertion or Bubble Sort) causes the maximum number of comparisons and swaps.
Average-Case Inputs:
For average-case experiments, arrays were generated randomly.
Uniformity Across Algorithms:
The same input for a given test case size was used for all algorithms to ensure a fair comparison. In our implementation, the input file is read once, and the same array is duplicated for each sorting algorithm.

6. QuickSort Variant Comparisons:

We implemented three versions of QuickSort:
QuickSortFirst: Uses the first element as the pivot.
QuickSortRandom: Chooses a random element as the pivot.
QuickSortMedian: Uses the median of the first, middle, and last elements as the pivot.
For each variant, we ran experiments for best-case, worst-case, and average-case inputs as described above.
